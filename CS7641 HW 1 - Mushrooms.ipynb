{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 7641 Homework 1 - Fall 2020\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import tree, svm, datasets, metrics\n",
    "from sklearn.model_selection import train_test_split,StratifiedKFold, StratifiedShuffleSplit, cross_validate, GridSearchCV\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from visualization import plot_2d_data, plot_2d_classifier\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "from visualization import get_colors\n",
    "cm = get_colors(colormap='RdBu', n_colors=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/vipulbahl/parkinson-disease-identification/download\n",
    "data = pd.read_csv(\"./data/mushrooms.csv\")\n",
    "data = data.apply(LabelEncoder().fit_transform)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation = data.corr()\n",
    "correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "sns.heatmap(correlation, annot=True, vmin=-1, vmax=1, center= 0, cmap= 'coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_X = data.drop(['class', 'veil-type'], axis=1)\n",
    "data_y = data['class']\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(data_X, data_y, test_size=0.2, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function\n",
    "def plot_confusionmatrix(y_train_pred,y_train,dom):\n",
    "    print(f'{dom} Confusion matrix')\n",
    "    cf = confusion_matrix(y_train_pred,y_train)\n",
    "    sns.heatmap(cf,annot=True,yticklabels=classes\n",
    "               ,xticklabels=classes,cmap='Blues', fmt='g')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/modules/tree.html\n",
    "# https://deepstat.tistory.com/44\n",
    "# https://jcabelloc.github.io/machine%20learning/2019/02/27/classification-task.html\n",
    "\n",
    "dtc = tree.DecisionTreeClassifier(random_state=100)\n",
    "dtc.fit(train_X, train_y)\n",
    "predict_y_train = dtc.predict(train_X)\n",
    "predict_y = dtc.predict(test_X)\n",
    "print(f\"Training accuracy score: {100* accuracy_score(train_y, predict_y_train)}%\")\n",
    "print(f\"Testing accuracy Score: {100* accuracy_score(test_y, predict_y)}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_learning_rate_steps, n_folds = 10, 10\n",
    "learning_rates = np.linspace(0.1, 1.0, num=n_learning_rate_steps)\n",
    "splitter = StratifiedKFold(n_splits=n_folds, shuffle=True)\n",
    "trn_err = np.zeros((n_learning_rate_steps, n_folds))\n",
    "val_err = np.zeros((n_learning_rate_steps, n_folds))\n",
    "stump = DecisionTreeClassifier(max_depth=1, random_state = 100)\n",
    " \n",
    "for i, rate in enumerate(learning_rates):\n",
    "    for j, (trn, val) in enumerate(splitter.split(heart_train_X, heart_train_y)):\n",
    "        model = AdaBoostClassifier(algorithm='SAMME', base_estimator=stump, \n",
    "                                   n_estimators=10, learning_rate=rate)\n",
    "        model.fit(heart_train_X.values[trn, :], heart_train_y.values[trn])\n",
    "        trn_err[i, j] = 1 - accuracy_score(heart_train_y.values[trn], model.predict(heart_train_X.values[trn, :]))\n",
    "        val_err[i, j] = 1 - accuracy_score(heart_train_y.values[val], model.predict(heart_train_X.values[val, :]))\n",
    "trn_err = np.mean(trn_err, axis=1)\n",
    "val_err = np.mean(val_err, axis=1)\n",
    "print(f'Training Error {trn_err}, Value Error {val_err}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(4, 4))\n",
    "\n",
    "ax.plot(learning_rates, trn_err, marker='o', c=cm[0], markeredgecolor='w', linewidth=2)\n",
    "ax.plot(learning_rates, val_err, marker='s', c=cm[1], markeredgecolor='w', linewidth=2)\n",
    "ax.legend(['Train err', 'Validation err'])\n",
    "ax.set_xlabel('Learning rate')\n",
    "ax.set_ylabel('Error (%)')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimator_steps, n_folds = 2, 10\n",
    "number_of_stumps = np.arange(2, 40, n_estimator_steps)\n",
    "splitter = StratifiedKFold(n_splits=n_folds, shuffle=True)\n",
    "\n",
    "trn_err = np.zeros((len(number_of_stumps), n_folds))\n",
    "val_err = np.zeros((len(number_of_stumps), n_folds))\n",
    "\n",
    "stump = DecisionTreeClassifier(max_depth=1)\n",
    "for i, n_stumps in enumerate(number_of_stumps):\n",
    "    for j, (trn, val) in enumerate(splitter.split(heart_train_X, heart_train_y)):\n",
    "        model = AdaBoostClassifier(algorithm='SAMME', base_estimator=stump,\n",
    "                                   n_estimators=n_stumps, learning_rate=1.0)\n",
    "        model.fit(heart_train_X.values[trn, :], heart_train_y.values[trn])\n",
    "\n",
    "        trn_err[i, j] = 1 - accuracy_score(heart_train_y.values[trn], \n",
    "                                           model.predict(heart_train_X.values[trn, :]))\n",
    "        val_err[i, j] = 1 - accuracy_score(heart_train_y.values[val], \n",
    "                                           model.predict(heart_train_X.values[val, :]))\n",
    "\n",
    "trn_err = np.mean(trn_err, axis=1)\n",
    "val_err = np.mean(val_err, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(4, 4))\n",
    "\n",
    "ax.plot(number_of_stumps, trn_err, marker='o', c=cm[0], markeredgecolor='w', linewidth=2)\n",
    "ax.plot(number_of_stumps, val_err, marker='s', c=cm[1], markeredgecolor='w', linewidth=2)\n",
    "ax.legend(['Train err', 'Validation err'])\n",
    "ax.set_xlabel('Number of decision stumps')\n",
    "ax.set_ylabel('Error (%)')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "shallow_tree = DecisionTreeClassifier(max_depth=1)\n",
    "ensemble = AdaBoostClassifier(base_estimator=shallow_tree, \n",
    "                                  n_estimators=16, learning_rate=0.75)\n",
    "ensemble.fit(heart_train_X, heart_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = ensemble.predict(heart_test_X)\n",
    "acc = accuracy_score(heart_test_y, ypred)\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = svm.SVC(kernel='rbf', C=30, gamma='auto')\n",
    "model.fit(heart_train_X, heart_train_y)\n",
    "model.score(heart_test_X, heart_test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import f1_score, make_scorer, classification_report\n",
    "\n",
    "# https://stackoverflow.com/questions/12632992/gridsearch-for-an-estimator-inside-a-onevsrestclassifier\n",
    "\n",
    "# model_OVRC = OneVsRestClassifier(svm.LinearSVC(class_weight='balanced', max_iter=10000))\n",
    "# svm_model = svm.LinearSVC(class_weight='balanced', max_iter=100000)\n",
    "svm_model = svm.SVC()\n",
    "\n",
    "parameters = {'C':(0.1, 0.5, 1, 2, 5, 10, 20, 40, 100), \n",
    "          \"gamma\":(0.001, 0.01, 0.1, 0.25, 0.5, 0.75, 1), \n",
    "          \"kernel\":('linear', 'poly', 'rbf')\n",
    "         }\n",
    "\n",
    "model = GridSearchCV(svm_model, parameters, cv=5)\n",
    "\n",
    "model.fit(heart_train_X, heart_train_y)\n",
    "model_predict = model.predict(heart_test_X)\n",
    "\n",
    "print(classification_report(heart_test_y, model_predict))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "KNN_Model = KNeighborsClassifier(n_neighbors=30).fit(heart_train_X, heart_train_y)\n",
    "\n",
    "# https://stackoverflow.com/questions/52910061/implementing-roc-curves-for-k-nn-machine-learning-algorithm-using-python-and-sci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_y_scores = KNN_Model.predict_proba(heart_test_X)\n",
    "fpr, tpr, threshold = roc_curve(heart_test_y, heart_y_scores[:, 1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.title('ROC Curve of kNN')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
